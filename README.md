# Left Ventricle Automatic Segmentation with Deep Learning on the EchoNet Dynamic Dataset

#### Team Members

- Omar Alejandro Rodríguez Valencia
- Cristian Javier Cázares Molina
- Jair Josué Jimarez García
- Musel Emmanuel Tabares Pardo
- Siddhartha López Valenzuela

## Introduction
Using the EchoNet Dynamic dataset, that contains a lot of images of different patient's echocardiograms, with Image Segmentation and Deep Learning (DL) techniques, we want to be able to predict the masks of the area of the left ventricle of every echocardiogram image. This can be helpful for medical experts to extract information and diagnose patients with greater ease.

### Scope
We want to determine the better model for this situation, between a Landmarks Model or a Masks Model. We choose the best model based on the accuracy of the masks generated by the model, that will be evaluated with new images that contains more noise than the ones that have been used for training. The training dataset contains clinical measurements and other information that will be ignored.

### Background
In the past, DL techniques have already been used in the medical field, for example, to detect cancerous cells [^1]. Usually, this projects that requires image segmentation, use the "Fully Convolutional Neural Networks"[^2], that focus on assing a class to each pixel of the image, and not label the image as whole. Past investigations have done masks of the heart's left ventricle, but they used magnetic resonance images, and they got acceptable results (87.24% dice score), so this suggests that our problem can be solved with a Fully Convolutional Neural Network.

## Data
The Stanford University data set have 10,030 echocardiography videos (approximately 7.9 GB) since 2016 until 2018 as part of routine clinical care. Each video has 100 frames, approximately; and every video was cropped to remove the text and information that is not relevant for the scanning process. All frames were resized into 112X112 pixels, and some frames were matched with their respective masks, that will be used to train the model. The masks are given as coordinates that represent essential points to identify the left ventricle at the echocardiogram image.

![image](https://github.com/Tec-AI-23/EchoNetDynamic/assets/83721976/bf563538-a787-429a-9169-a594d3a0e808)

Like we said before, the data set contains clinical measurements that will be ignored, since we only want to generate masks tracing the left ventricle. As the data is from the Stanford University, we assume that it follows laws concerning privacy on medical data. The data set can be found in the Stanford web page. The data set will be stored only locally to avoid any possible disturb.

[^1]: Nasim, M. A. A., Munem, A. A., Islam, M., Palash, M. A. H., Haque, M. M. A., & Shah, F. M. (2023). Brain tumor segmentation using enhanced u-net model with empirical analysis.
[^2]: Long, J., Shelhamer, E., & Darrell, T. (2015, June). Fully convolutional net-works for semantic segmentation. In Proceedings of the ieee conference on computer vision and pattern recognition (cvpr).
